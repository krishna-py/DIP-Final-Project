{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DRIVE dataset\n",
    "dataset = Path('data/DRIVE')\n",
    "\n",
    "# Load the training dataset\n",
    "train_images = sorted(dataset.glob('training/images/*.tif'))\n",
    "train_labels = sorted(dataset.glob('training/1st_manual/*.gif'))\n",
    "train_mask = sorted(dataset.glob('training/mask/*.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images), train_images[:3], train_labels[:3], train_mask[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_images = sorted(dataset.glob('test/images/*.tif'))\n",
    "test_mask = sorted(dataset.glob('test/mask/*.gif'))\n",
    "len(test_images), test_images[:3], test_mask[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample image, mask and label\n",
    "image = Image.open(train_images[0])\n",
    "mask = Image.open(train_mask[0])\n",
    "label = Image.open(train_labels[0])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(131)\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image {image.size}, {image.mode}')\n",
    "plt.subplot(132)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(f'Mask {mask.size}, {mask.mode}')\n",
    "plt.subplot(133)\n",
    "plt.imshow(label, cmap='gray')\n",
    "plt.title(f'Label {label.size}, {label.mode}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the image in R,G,B channels\n",
    "red, green, blue = image.split()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(141)\n",
    "plt.imshow(image)\n",
    "plt.subplot(142)\n",
    "plt.imshow(red)\n",
    "plt.title('red')\n",
    "plt.subplot(143)\n",
    "plt.imshow(green)\n",
    "plt.title('green')\n",
    "plt.subplot(144)\n",
    "plt.imshow(blue)\n",
    "plt.title('blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing training images\n",
    "\n",
    "# 1. take only the green channel\n",
    "# 2. apply morphological opening with a three-pixel diameter disk structuring element\n",
    "# 3. The local background gray level is computed by applying a 69Ã—69 mean filter to the image. The\n",
    "# background is then subtracted and the resulting gray levels are scaled from 0 to 1.\n",
    "# 4. a constant is added to the image gray levels so the mode gray level value in image is set to 0.5\n",
    "# 5.  top-hat transformation on the complement of the image using an eight-pixel radius\n",
    "# disk as the structuring element\n",
    "# \n",
    "\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "from skimage import img_as_float\n",
    "from skimage import transform\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    # Convert the image and mask to float32 tensors\n",
    "    image = img_as_float(image)\n",
    "    mask = img_as_float(mask)\n",
    "    \n",
    "    # Take only the green channel\n",
    "    image = image[:, :, 1]\n",
    "    \n",
    "    # Apply morphological opening with a 3-pixel disk structuring element\n",
    "    selem = morphology.disk(3)\n",
    "    image = morphology.opening(image, selem)\n",
    "    \n",
    "    # Compute the local mean of the image\n",
    "    local_mean = filters.rank.mean(image, selem)\n",
    "    \n",
    "    # Subtract the local mean from the image\n",
    "    image = image - local_mean\n",
    "    \n",
    "    # Scale the image so that its values range from 0 to 1\n",
    "    image = exposure.rescale_intensity(image)\n",
    "    \n",
    "    # Add a constant to the image so that its minimum value is 0\n",
    "    image = image - image.min()\n",
    "    \n",
    "    # Normalize the image so its values sum to 1\n",
    "    image = image / image.sum()\n",
    "    \n",
    "    # Apply a top-hat transformation to the image\n",
    "    selem = morphology.disk(8)\n",
    "    image = morphology.white_tophat(image, selem)\n",
    "    \n",
    "    # Normalize the image so its values sum to 1\n",
    "    image = image / image.sum()\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    image = image * mask\n",
    "    \n",
    "    # # Convert the image and the mask to PyTorch tensors\n",
    "    # image = torch.from_numpy(image).unsqueeze(0)\n",
    "    # mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_image = preprocess(image, mask)\n",
    "print(p_image.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(121)\n",
    "plt.title(f'Preprocessed image {p_image.shape}')\n",
    "plt.imshow(p_image, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title(f'ground truth {label.size}')\n",
    "plt.imshow(label, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction from preprocessed image\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "windows = sliding_window_view(p_image, (9, 9))\n",
    "windows.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_windows = sliding_window_view(label, (9, 9))\n",
    "label_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the windows randomly\n",
    "\n",
    "plt.figure(figsize=(80, 16))\n",
    "for i in range(40):\n",
    "    xidx = random.randint(0, windows.shape[0])\n",
    "    yidx = random.randint(0, windows.shape[1])\n",
    "\n",
    "    if i < 20:\n",
    "        plt.subplot(4, 20, i+1)\n",
    "        plt.imshow(windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        plt.subplot(4, 20, i+21)\n",
    "        plt.imshow(label_windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        if i == 0:\n",
    "            plt.title(f'window {xidx}, {yidx}')\n",
    "            plt.title(f'label {xidx}, {yidx}')\n",
    "\n",
    "    if i >= 20:\n",
    "        plt.subplot(4, 20, i-20+41)\n",
    "        plt.imshow(windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        plt.subplot(4, 20, i-20+61)\n",
    "        plt.imshow(label_windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        if i == 20:\n",
    "            plt.title(f'window {xidx}, {yidx}')\n",
    "            plt.title(f'label {xidx}, {yidx}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the features of the image\n",
    "# for each image in the dataset, implement the below steps\n",
    "# 1. take the image and mask and preprocess the image\n",
    "# 2. Compute the following features on the preprocessed image, in a 9x9 window around each pixel in the image.\n",
    "#   a. intensity of center pixel\n",
    "#  b. absolute difference between the intensity of center pixel and min, max and mean intensity of the window\n",
    "# c. standard deviation of the window\n",
    "\n",
    "def extract_features(p_image):\n",
    "    # Compute the window\n",
    "    windows = sliding_window_view(p_image, (9, 9)).copy()\n",
    "\n",
    "    # pixel centers\n",
    "    centers = windows[:, :, 4, 4]\n",
    "\n",
    "    # min, max, mean, and standard deviation of each window\n",
    "    w_min, w_max, w_mean, w_std = windows.min(axis=(2, 3)), windows.max(axis=(2, 3)), windows.mean(axis=(2, 3)), windows.std(axis=(2, 3))\n",
    "\n",
    "    # features\n",
    "    features = np.stack([centers, np.abs(centers - w_min), np.abs(centers - w_max), np.abs(centers - w_mean), w_std], axis=2)\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(label):\n",
    "    # Compute the window\n",
    "    windows = sliding_window_view(label, (9, 9)).copy()\n",
    "\n",
    "    # pixel centers\n",
    "    centers = windows[:, :, 4, 4]\n",
    "\n",
    "    # labels\n",
    "    labels = (centers > 0).astype(np.uint8)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = extract_labels(label)\n",
    "label.size, label_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, mask_path, label_path in zip(train_images, train_mask, train_labels):\n",
    "    print(image_path, mask_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "\n",
    "for image_path, mask_path in zip(train_images, train_mask):\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path)\n",
    "\n",
    "    p_image = preprocess(image, mask)\n",
    "    print(p_image.shape)\n",
    "    features = extract_features(p_image)\n",
    "    print(features.shape)\n",
    "    train_features.append(features)\n",
    "    print(f'Extracted {features.shape} features from {image_path.name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "for label_path in train_labels:\n",
    "    labels = extract_labels(label)\n",
    "    print(labels.shape)\n",
    "    train_y.append(labels)\n",
    "    print(f'Extracted {labels.shape} labels from {label_path.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.stack(train_features), np.stack(train_y)\n",
    "train_set[0].shape, train_set[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all images in test set, extract the features\n",
    "test_features = []\n",
    "for image_path, mask_path in zip(test_images, test_mask):\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path)\n",
    "\n",
    "    p_image = preprocess(image, mask)\n",
    "    features = extract_features(p_image)\n",
    "    test_features.append(features)\n",
    "    print(f'Extracted {features.shape} features from {image_path.name}')\n",
    "\n",
    "test_set = np.stack(test_features)\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the train_set and test_set\n",
    "\n",
    "np.savez_compressed('data/DRIVE/train_set.npz', X=train_set[0], y=train_set[1])\n",
    "np.savez_compressed('data/DRIVE/test_set.npz', X=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling postive and negative examples from train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train_set and test_set\n",
    "train_set = np.load('data/DRIVE/train_set.npz', allow_pickle=True)\n",
    "test_set = np.load('data/DRIVE/test_set.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['X'].shape, train_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_set['y'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_set['y'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive samples\n",
    "pos_samples = train_set['X'][train_set['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of negative samples\n",
    "\n",
    "neg_samples = train_set['X'][train_set['y'] == 0]\n",
    "neg_samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the std of negative samples\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(neg_samples[:, -1].ravel(), bins=100)\n",
    "plt.title('std of negative samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling the negative samples equal to the number of positive samples\n",
    "sample_neg_idx = np.random.choice(np.arange(neg_samples.shape[0]), size=train_set['y'].sum())\n",
    "sample_neg = neg_samples[sample_neg_idx]\n",
    "sample_neg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the std of negative samples\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(sample_neg[:, -1].ravel(), bins=100)\n",
    "plt.title('std of negative samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced dataset = positive samples + negative samples\n",
    "balanced_x = np.concatenate([pos_samples, sample_neg], axis=0)\n",
    "balanced_y = np.concatenate([np.ones(pos_samples.shape[0]), np.zeros(sample_neg.shape[0])], axis=0)\n",
    "balanced_x.shape, balanced_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling of balanced_x\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "balanced_x = scaler.fit_transform(balanced_x.reshape(-1, 5)).reshape(balanced_x.shape)\n",
    "balanced_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_y.sum(), np.unique(balanced_y, return_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('data/DRIVE/balanced_train_set.npz', X=balanced_x, y=balanced_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Network using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch dataloader for balanced data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DRIVE(Dataset):\n",
    "    def __init__(self, M=30000):\n",
    "        super().__init__()\n",
    "        balanced_set = np.load('data/DRIVE/balanced_train_set.npz')\n",
    "        samples = np.random.choice(np.arange(balanced_set['X'].shape[0]), size=M)\n",
    "        self.X = balanced_set['X'][samples].astype(np.float32)\n",
    "        self.y = balanced_set['y'].reshape(-1,1)[samples].astype(np.float32)\n",
    "\n",
    "        print('Loaded the dataset', self.X.shape, self.X.dtype, self.y.shape, self.y.dtype)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP with 5 inputs, three hidden layers with 15 nodes each, and one output\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=[15,15,15], output_size=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.p_dropout = dropout\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        for i in range(1, len(hidden_size)):\n",
    "            setattr(self, f'fc{i+1}', nn.Linear(hidden_size[i-1], hidden_size[i]))\n",
    "        self.fc4 = nn.Linear(hidden_size[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu6(self.fc1(x))\n",
    "        x = F.relu6(self.fc2(x))\n",
    "        x = F.relu6(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=5, out_features=15, bias=True)\n",
      "  (fc2): Linear(in_features=15, out_features=15, bias=True)\n",
      "  (fc3): Linear(in_features=15, out_features=15, bias=True)\n",
      "  (fc4): Linear(in_features=15, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset (30000, 5) float32 (30000, 1) float32\n",
      "\tEpoch 0 | Batch 0 | Loss   0.69\n",
      "Epoch 0 | Loss   0.69\n",
      "\tEpoch 1 | Batch 0 | Loss   0.68\n",
      "Epoch 1 | Loss   0.68\n",
      "\tEpoch 2 | Batch 0 | Loss   0.67\n",
      "Epoch 2 | Loss   0.66\n",
      "\tEpoch 3 | Batch 0 | Loss   0.66\n",
      "Epoch 3 | Loss   0.64\n",
      "\tEpoch 4 | Batch 0 | Loss   0.64\n",
      "Epoch 4 | Loss   0.63\n",
      "\tEpoch 5 | Batch 0 | Loss   0.62\n",
      "Epoch 5 | Loss   0.62\n",
      "\tEpoch 6 | Batch 0 | Loss   0.60\n",
      "Epoch 6 | Loss   0.61\n",
      "\tEpoch 7 | Batch 0 | Loss   0.63\n",
      "Epoch 7 | Loss   0.60\n",
      "\tEpoch 8 | Batch 0 | Loss   0.60\n",
      "Epoch 8 | Loss   0.60\n",
      "\tEpoch 9 | Batch 0 | Loss   0.59\n",
      "Epoch 9 | Loss   0.59\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "epochs = 10\n",
    "BATCH_SIZE = 1024\n",
    "lr = 0.01\n",
    "\n",
    "train_set = DRIVE()\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for batch_num, input_data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = input_data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 40 == 0:\n",
    "            print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "    print('Epoch %d | Loss %6.2f' % (epoch, sum(losses)/len(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
